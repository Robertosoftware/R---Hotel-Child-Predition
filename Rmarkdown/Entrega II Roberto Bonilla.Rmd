---
title: "Entrega II Individual"
description: |
  Entrega SEMMA
author:
  - name: Roberto Bonilla Ibarra
    url: 
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output:
    distill::distill_article:
        highlight: kate
        colorlinks: true
        code_folding: false
        toc: true            
        toc_depth: 3     
---

```{r setup, include = FALSE}
# Ajuste comunes de los chunk
knitr::opts_chunk$set(fig.width = 8, fig.asp = 1, out.width = "100%",
                      message = FALSE, warning = FALSE,
                      echo = TRUE, res = 400)
```

# Objetivo {#objetivo}

El objetivo de esta entrega es poder predecir si los individuos recibir谩n un sueldo mayor o menor o igual a 50 mil d贸lares mensuales basado en sus caracter铆sticas socioecon贸micas, usando tres diferentes algoritmos de clasificaci贸n (knn, 谩rboles y random forest).

## Paquetes necesarios

Necesitaremos los siguientes paquetes

* **An谩lisis exploratorio num茅rico**: paquete `{skimr}`
* **Depuraci贸n y preprocesamiento**: paquete `{tidyverse}`
* **Modelizaci贸n**: paquete `{tidymodels}` para modelos
* **Detecci贸n de outliers**: paquete `{outliers}`


```{r paquetes}
# Borramos
rm(list = ls())

# Paquetes
library(skimr) # resumen num茅rico
library(tidymodels) # depuraci贸n datos
library(tidyverse) # modelos
library(outliers) # outliers
library(timeDate) # fechas
library(ggthemes) # tema para graficar
```

# Datos {#datos}

Vamos ir a un **ejemplo real**, haciendo uso de un **dataset de adultos con distintas variables socioecon贸micas.**

```{r}
adultos <- read_csv(file = "./datos/adults.csv")
```

Los datos forman parte de un **censo poblacional relacionado a la percepci贸n econ贸mica** elaborado por US Census Bureau con 32,561 registros.

 **Detalle de variables**: <http://www.cs.toronto.edu/~delve/data/adult/adultDetail.html1>



## An谩lisis exploratorio inicial (num茅rico)

Antes de tomar ninguna decisi贸n con los datos lo primero que deber铆amos hacer es **echar un vistazo num茅rico** a c贸mo se comportan las variables. Dado que vamos a clasificar, lo primero que deber铆amos observar es como se distribuyen los niveles de nuestra variable objetivo.

### Variables

Lo primero es conocer las variables

```{r}
glimpse(adultos)
```

* `age`: Edad de los individuos
* `workclass`: Tipo de trabajo de cada individuo
* `fnlwgt`: N煤mero de personas con la misma edad y raza.
* `education,education_num`: Nivel de educaci贸n m谩ximo
* `marital_status`: Situaci贸n sentimental del individuo.
* `occupation`: A lo que se dedica el individuo
* `relationship`: Cu谩l es la relaci贸n que tiene con su familia.
* `race`: Raza del individuo
* `sex`: Sexo del individuo
* `capital_gain`: Capital percibido
* `capital_loss`: Capital perdido
* `hours_per_week`: Horas de trabajo semanales
* `native_country`: Pa铆s de origen
* `over_50k`: Si el individuo percibe un ingreso mayor a 50 mil d贸lares anuales o menor o igual a este.


Adem谩s con la funci贸n `skim()` del paquete `{skimr}` podemos **extraer algunas estad铆sticas b谩sicas** de nuestros datos.

```{r skim}
# Resumen num茅rico
adultos |> skim()
```

Veamos los tipos de dato de las variables:

```{r}
sapply(adultos, class)
```

Podemos ver que tenemos que cambiar el tipo de dato de la variable capital loss y capital gain, veamos su distribuci贸n,

**Capital Gain**
```{r}
adultos |> 
  count(capital_gain) |>
  mutate(porc = 100*n/sum(n))

```

**Capital Loss**

```{r}
adultos |> 
  count(capital_loss) |>
  mutate(porc = 100*n/sum(n))
```

Hemos visto que son variables continuas, por la tanto las convertiremos en num茅ricas:

```{r}
adultos$capital_gain <- as.numeric(str_replace_all(adultos$capital_gain,',',''))
adultos$capital_loss <- as.numeric(str_replace_all(adultos$capital_loss,',',''))
```


### Balance la variable objetivo

El objetivo ser谩 **predecir si un adulto est谩 destinado a recibir un ingreso mayor a 50 mil d贸lares anuales o menor o igual a este**, por lo que la variable `over_50k` ser谩 nuestra variable objetivo. Primer paso: conocer c贸mo se **distribuyen los niveles de la objetivo** (es binaria)


```{r}
adultos |> 
  count(over_50k) |>
  mutate(porc = 100*n/sum(n))
```

Podemos ver que nuestra variable objetivo est谩 desbalanceada hacia las personas con un ingreso menor o igual a 50 mil d贸lares.


# An谩lisis Exploratorio Visual

Antes de poder tomar decisiones en c贸mo transformar nuestros datos es importante poder hacer un an谩lisis detallado visual de nuestros datos y conocer c贸mo interact煤an con la variable objetivo:

Para esto usaremos el tema del economist del paquete ggplothemes

## Distribuci贸n visual variable objetivo

La Variable Objetivo se encuentre desbalanceda, teniendo un 75% de casos donde las personas ganan menos que 50 mil d贸lares al a帽o.

```{r}
ggplot(adultos, aes(x = over_50k, fill = over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  scale_fill_brewer(palette = "Dark2") +
  labs(title = "Variable objetivo",
       subtitle = "Distribuci贸n de ingresos",
       x = "Cantidad", y = "Frecuencia") +
  theme_economist()

```


## Distribuci贸n visual variables continuas

### Variable Edad

```{r}
ggplot(adultos, aes(x = age, fill = over_50k)) +
    geom_density(alpha = .3) +
    labs(title = "Variable Edad",
       subtitle = "Distribuci贸n de Edad con diferencia de Variable Objetivo",
       x = "Edad", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que las personas que ganan m谩s de 50 mil d贸lares al a帽o tienden a ser de mayor edad en comparaci贸n con los que hacen menos o igual a 50 mil d贸lares al a帽o, tambi茅n podemos ver que la mayor铆a est谩n entre 30 y 55 a帽os.

```{r}
ggplot(adultos, aes(x = over_50k, y = age, color=over_50k)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Variable Edad",
       subtitle = "Distribuci贸n de Edad por Tipo de Ingreso",
       x = "Over 50k", y = "Cantidad") +
  theme_economist()
```

### Variable Capital Gain

Ahora veamos como se comporta la variable de Capital Ganado

```{r}
ggplot(adultos, aes(x = capital_gain, fill = over_50k)) +
    geom_density(alpha = .6) + # Grado de transparencia para ver la gr谩fica traspuesta
  scale_y_continuous(limits = c(0, .0001)) + # Para poder visualizar mejor la gr谩fica
    labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci贸n de Capital Ganado con diferencia de Variable Objetivo",
       x = "Capital Ganado", y = "Frecuencia") +
  theme_economist()
```


Podemos ver que las personas que perciben un ingreso mayor a 50K USD tienden a tener capital ganado en comparaci贸n con los que no perciben un ingreso mayor a 50k USD.

```{r}
ggplot(adultos |>  filter(capital_gain<20000), aes(x = capital_gain, fill = over_50k)) +
    geom_histogram(position = "identity", alpha = 0.4, bins=20) + # Posici贸n identity para que se puedan trasponer los histogramas
     labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci贸n de Capital Ganado con diferencia de Variable Objetivo",
       x = "Capital Gain", y = "Frecuencia") +
  theme_economist()
```


Podemos corroborar lo que mencionamos arriba, donde si bien la mayor铆a de las personas no ganan capital, cuando ellas documentan que perciben cierto capital tienen m谩s probabilidad de ser del grupo de personas que perciben un ingreso mayor a 50 K USD.

```{r}
ggplot(adultos, aes(x = capital_gain, y = education, color=over_50k)) +
  geom_point() +
   labs(title = "Variable Capital Ganado",
       subtitle = "Distribuci贸n de Capital Ganado por Educaci贸n") +
  theme_economist()
```

Podemos ver que las personas que tienen un nivel acad茅mico bajo tienden a reportar un capital ganado bajo o nulo y a la vez este repercute en el ingreso anual que perciben en el a帽o.

### Variable Capital Loss

Ahora analizaremos la variable de Capital Perdido

```{r}
ggplot(adultos, aes(x = over_50k, y = capital_loss, color=over_50k)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape = 23, size = 3, fill = "white") +
   labs(title = "Variable Capital Perdido",
       subtitle = "Distribuci贸n del Capital Perdido",
       x = "Over 50k", y = "Cantidad") +
  theme_economist()
```

Podemos ver que los percentiles 25, 50 y 75 se encuentran en 0, se帽alando que la mayor parte de las personas no tienen capital perdido, sin embargo al ver la distribuci贸n podemos determinar que en el caso que una persona tenga perdida de capital, es muy probable que si ella percibe un ingreso menor a 50 mil USD sea baja y visceversa, determinando esto tambi茅n por donde se posiciona la media de cada grupo. (Las personas conun ingreso m谩s alto son menos en los casos de perdida, sin embargo, su media es m谩s alta) 

```{r}

ggplot(adultos, aes(x = capital_loss, fill = over_50k)) +
    geom_density(alpha = .6) +
  scale_y_continuous(limits = c(0, .002)) +
    labs(title = "Variable Capital Perdido",
       subtitle = "Distribuci贸n de Capital Perdidoe con diferencia por Tipo de Ingreso",
       x = "Capital Perdido", y = "Frecuencia") +
  theme_economist()
```

Esta gr谩fica confirma la observaci贸n marcada anteriormente con respecto al capital perdido, lo importante a resaltas es que al ser est谩 gr谩fica la densidad de la distribuci贸n se aprecia de mejor manera.

### Variable Hours_per_week

```{r}

ggplot(adultos, aes(x =  hours_per_week, fill = over_50k)) +
    geom_density(position = "identity", alpha = 0.4, bins=20) +
    labs(title = "Variable Horas a la Semana",
       subtitle = "Distribuci贸n de Horas a la Semana con diferencia de Variable Objetivo",
       x = "Horas a la Semana", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que las personas con un ingreso 

### Variable fnlwgt


```{r}

ggplot(adultos, aes(x = fnlwgt, fill = over_50k)) +
    geom_density(alpha = .3) +
    labs(title = "Variable fnlwgt",
       subtitle = "Distribuci贸n de Fnlwgt con diferencia de Variable Objetivo",
       x = "Fnlwgt", y = "Frecuencia") +
  theme_economist()
```

Podemos ver que no existe ning煤n patr贸n entre las dos distribuciones.

## Distribuci贸n visual variables continuas

### Variable Clase de Trabajo

Analizaremos la variable **Clase de Trabajo** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = workclass, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Clases de Trabajo",
       subtitle = "Distribuci贸n de Clases de Trabajo",
       x = "Personas", y = "Clases de Trabajo") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

### Variable Estado Civil

Analizaremos la variable **Estado Civil** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = marital_status, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Estado Civil",
       subtitle = "Distribuci贸n del Estado Civil",
       x = "Personas", y = "Estado Civil") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver un comportamiento muy importante en la clase donde la gente se ha casado de manera civil, teniendo una gran cantidad y proporci贸n mucho m谩s favorable para los individuos que ganan m谩s de 50 mil USD al a帽o.

### Variable Ocupaci贸n

Analizaremos la variable *Ocupaci贸n** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = occupation, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Ocupaci贸n",
       subtitle = "Distribuci贸n de la variable Ocupaci贸n",
       x = "Personas", y = "Ocupaci贸n") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Como era de esperarse las clases que hacen una diferencia en su distribuci贸n son **Prof-Speciality** y **Exec-Managerial** por el tipo de ingreso que llevan estos dos grupos de personas.

### Variable Relaci贸n

Analizaremos la variable *Relaci贸n** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = relationship, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Relaci贸n",
       subtitle = "Distribuci贸n de la variable Relaci贸n",
       x = "Personas", y = "Relaci贸n") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Vemos aqu铆 que los jedes de familia son en su mayor铆a los que perciben un ingreso mayor a 50 mil d贸lares anuales.

### Variable Raza

Analizaremos la variable *Raza** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = race, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Raza",
       subtitle = "Distribuci贸n de la variable Raza",
       x = "Personas", y = "Raza") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que los asi谩ticos y blancos son los m谩s propensos a percibir un ingreso superior a 50 mil d贸lares anuales.

### Variable Sexo

Analizaremos la variable *Sexo** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = sex, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Sexo",
       subtitle = "Distribuci贸n de la variable Sexo",
       x = "Personas", y = "Sexo") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(count)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que al agruparse la poblaci贸n, el sexo masculino tiene una mayor posibilidad de percibir un ingreso superior a 50 mil d贸lares anuales.


### Variable Pa铆s

Analizaremos la variable *Pa铆s** y su relaci贸n con la variable objetivo:

```{r}
  ggplot(adultos, aes(y = native_country, fill=over_50k)) +
  geom_bar(color = "white", alpha = 0.3) +
  labs(title = "Variable Pa铆s",
       subtitle = "Distribuci贸n de la variable Pa铆s en %",
       x = "Personas", y = "Pa铆s") +
  geom_text(size = 2.5,stat='count', aes(label=after_stat(round(count / sum(count),2) * 100)), position=position_stack(vjust=0.5)) + 
  theme_economist()
```

Podemos ver que alrededor del 90% de las personas han nacido en Estados Unidos.

### Variable 

# Introducci贸n Te贸rica

Explicaremos brevemente cada uno de los algoritmos que se usar谩n en esta pr谩ctica:


## KNN

Es uno de los modelos de Machine Learning m谩s sencillos. 

Su l贸gica es asumir la similaridad entre un nuevo caso o dato y los otros puntos disponibles, colocando este nuevo punto en las categor铆as previamente definidas.

Algoritmo usado para regresi贸n y clasificaci贸n.

Es un algoritmo de aprendizaje vago (lazy learner algorithm) ya que hace un almacenamiento de los datos de entrenamiento y espera hasta que reciba los datos de testing para poder empezar a clasificar, haciendo que tome menos tiempo en entrenamiento, pero m谩s tiempo prediciendo.


El funcionamiento del algoritmo de KNN es el siguiente:

**Paso 1**: 
**Paso 2**:
**Paso 3**:
**Paso 4**:
**Paso 5**:
**Paso 6**:

```{r echo = FALSE, results = 'asis'}
image = "https://datascientest.com/es/wp-content/uploads/sites/7/2020/11/Illu-2-KNN-1024x492.jpg"
cat(paste0('<center><img src="', image,  '"></center>')) 
```

Fuente: <https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning>

## rboles de decisi贸n

Los arboles de decisi贸n es un modelo de aprendizaje supervisado que sive para resolver problemas de clasificaci贸n y regresi贸n, tambi茅n conocido como `Classification And Regression Tree (CART) algorithm.`

Con base a la variable objetivo podemos definir los 谩rboles de decisi贸n en dos tipos:

1. Arboles de Decisi贸n de Variables Categ贸ricas
2. Arboles de Decisi贸n de Variables Continuas

Para


## Random Forest





# Fase 1-2-3: muestreo-exploraci贸n-modificaci贸n

Ahora examinaremos los datos con el objetivo de poder tomar **decisiones que deber铆amos adoptar**. Por ejemplo:

&nbsp;

* 驴Necesitamos **muestreo**? 驴De qu茅 forma? 驴Podremos permitirnos crear un dataset de **validaci贸n**?

* 驴De qu茅 **tipo** es cada variable? 驴Tenemos **problemas de codificaci贸n o rango**?

* 驴C贸mo **afectan las predictoras** a los niveles de la variable objetivo?

* 驴Hay problemas de **dependencia** entre las variables?

* 驴Necesitamos **recategorizar** las variables? 

* 驴Tenemos **datos at铆picos**?  驴Tenemos **datos ausentes**? 驴C贸mo imputarlos?

* 驴Necesitaremos hacer **One Hot Encoding** a nuestras variables categ贸ricas?

&nbsp;

La **filosof铆a** ser谩 la siguiente: 

* modificaciones 芦estructurales禄 las hacemos fuera de la receta (modificando la base de datos)

* modificaciones m谩s concretas para un algoritmo dentro de la receta (sin modificar la base de datos).

## Factores

Una de las primeras decisiones ser谩 dotar a las variables de su **tipolog铆a correcta**: debemos decidir si las variables de tipo texto son **variables cualitativas** (factores) o meros id's.

```{r}
adultos |>
  select(where(is.character)) |>
  glimpse()
```


Todas las variables de tipo texto representan **categor铆as de una cualitativa** as铆 que las convertimos todas ellas a factor (modificaci贸n estructural --> fuera de la receta)

```{r}

adultos <- 
  adultos |>
  mutate(across(where(is.character),  ~str_replace_all(., ",", "")), across(where(is.character), as_factor))
adultos |> select(where(is.factor))
```

### Ordinales

Podemos ver que de todas nuestras variables la educaci贸n puede tener un orden en sus variables.

Primero veamos su distribuci贸n:

```{r}
adultos |>
  count(education) |> 
  mutate(porc = 100*n/sum(n))
```

Vemos que son 16 niveles de variable que reduciremos a 5 niveles.

Pero primero les quitaremos la coma al final


```{r}

adultos <- adultos |> 
 mutate(
    education_transformed = as.factor(case_when(
      education == "Doctorate"  ~ as.character("Grado 5"),
      education == "Prof-school" | education == "Masters"  ~ as.character("Grado 4"),
      education == "Some-college" | education == "Bachelors"  ~ as.character("Grado 3"),
      education == "Assoc-acdm" | education == "Assoc-voc"  ~ as.character("Grado 2"),
      TRUE ~ as.character("Grado 1")
    )))

knitr::kable(adultos |> select(education, education_transformed) |>  unique())
```


Tras ello convertiremos `education_transformed` a cualitativa pero ordinal.

```{r}
adultos <-
  adultos |>
  mutate(education_transformed = factor(education_transformed, levels = c("Grado 1", "Grado 2", "Grado 3", "Grado 4", "Grado 5"),
                       ordered = TRUE))
knitr::kable(adultos |> select(education_transformed) |> arrange(desc(education_transformed)) |> unique() )
```


## Variables cuali

Una vez convertidas en cualitativas analicemos cada una de ellas. La idea b谩sica es la siguiente: ver que peso suponen cada nivel en las variables, y adem谩s, ver como **afectan los niveles a la variable objetivo**.

### Variable workclass

Ahora procederemos a ver c贸mo se distribuye la variable **clase de trabajo**:

```{r}
adultos |>
  count(workclass, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(workclass) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Self-emp-inc` y `Self-emp-not-inc` en un nuevo grupo llamado `Self-Emp` , as铆 como `Local-Gov` y `State-Gov` en `Other-Gov`. Tambi茅n renombraremos el tipo **?** a `Desconocido`.

```{r}

adultos <- adultos |> 
 mutate(
    workclass_transformed = as.factor(case_when(
      workclass == "?"  ~ as.character("Desconocido"),
      workclass == "Local-gov" | workclass == "State-gov"  ~ as.character("Other-Gov"),
      workclass == "Self-emp-inc" | workclass == "Self-emp-not-inc"  ~ as.character("Self-Emp"),
      TRUE ~ as.character(workclass)
    )))

knitr::kable(adultos |> select(workclass, workclass_transformed) |>  unique())
```

### Variable Estado Civil

Ahora procederemos a ver c贸mo se distribuye la variable **Estado Civil**:

```{r}
adultos |>
  count(marital_status, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(marital_status) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Married-civ-spouse` y `Married-AF-spouse` en un nuevo grupo llamado `Married` , as铆 como `Divorced`, `Separated`, `Widowed` y `Married-spouse-absent` en `Complicated`.

```{r}

adultos <- adultos |> 
 mutate(
    marital_status_transformed = as.factor(case_when(
      marital_status == "Married-civ-spouse" | marital_status == "Married-AF-spouse"  ~ as.character("Married"),
      marital_status == "Never-married"  ~ as.character("Never-married"),
      TRUE ~ as.character("Complicated")
    )))

knitr::kable(adultos |> select(marital_status, marital_status_transformed) |>  unique())
```



### Variable Ocupaci贸n

Ahora procederemos a ver c贸mo se distribuye la variable **Ocupaci贸n**:

```{r}
adultos |>
  count(occupation, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(occupation) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que hacen sentido como  `Prof-specialty` y `Exec-managerial` en un nuevo grupo llamado `High-Income` , as铆 como `Protective-serv`, `Tech-support` y `Sales` en `Medium-Income` y el resto en `Low-Income`.

```{r}

adultos <- adultos |> 
 mutate(
    occupation_transformed = as.factor(case_when(
      occupation == "Prof-specialty" | occupation == "Exec-managerial"  ~ as.character("High-Income"),
      occupation == "Protective-serv" | occupation == "Tech-support" | occupation == "Sales"   ~ as.character("Medium-Income"),
      TRUE ~ as.character("Low-Income")
    )))

knitr::kable(adultos |> select(occupation, occupation_transformed) |>  unique())
```

### Variable Relaci贸n

Ahora procederemos a ver c贸mo se distribuye la variable **Relaci贸n**:

```{r}
adultos |>
  count(relationship, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(relationship) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```

Podemos apreciar que existen ciertas agrupaciones que pueden hacer sentido como  `Wife` y `Husband` en un nuevo grupo llamado `Boss` , as铆 como el resto en un grupo llamado `Otros`. Esto lo haremos directamente en la receta para dejar al algorimto KNN con esta transformaci贸n y el resto de los algoritmos sin esta transformaci贸n.


### Variable Raza

Ahora procederemos a ver c贸mo se distribuye la variable **Raza**:

```{r}
adultos |>
  count(race, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(race) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso solo hace sentido agrupar `Amer-Indian-Eskimo` y `Other` en el grupo `Others`, las variables ya que son pocas y concisas, esto lo haremos directamente en la receta.


### Variable Sexo

Ahora procederemos a ver c贸mo se distribuye la variable **Sexo**:

```{r}
adultos |>
  count(sex, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(sex) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso no hace sentido agrupar ya que son dos categor铆as muy presentes.

### Variable Pa铆s

Ahora procederemos a ver c贸mo se distribuye la variable **Pa铆s**:

```{r}
adultos |>
  count(native_country, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumsum(porc))


adultos  |> group_by(native_country) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 

```
En este caso solo hace sentido dejar `United States` en un grupo, `Mexico` en otro grupo, `Philippines`,`Germany`,`Canada`,`India`,`England`,`South`,`Italy`,`Japan` y `Taiwan` en el grupo `High Income`, y el resto en el grupo `Others`.

```{r}

adultos <- adultos |> 
 mutate(
    country_transformed = as.factor(case_when(
      native_country %in% c("Philippines","Germany","Canada","India","England","South","Italy","Japan","Taiwan")  ~ "High-Income",
      native_country == "United-States"   ~ as.character(native_country),
      native_country == "Mexico"   ~ as.character(native_country),
      TRUE ~ as.character("Others")
    )))

knitr::kable(adultos |> select(native_country, country_transformed) |>  unique())
```


## Dependencia entre  cuali

Podemos ejecutar un **contraste de independencia** (prueba $\chi^2$ de independencia) para tener mayor certeza de si la predictora es dependiente o no de la variable objetivo (si fuera independiente, no tendr铆a sentido mantenerla)

Podemos hacerlo con **todas las variables a la vez** enfrent谩ndola a la objetivo, entendiendo que cada columna juega el rol de una lista si usamos las funciones del paquete `{purrr}`

```{r warning = FALSE}
chisq <-
  tibble("variable" = adultos |> select(where(is.factor)) |> names(),
         "p_value" = adultos |> select(where(is.factor)) |>
           map_dbl(.f = function(x) { chisq.test(adultos$over_50k, x)$p.value}))
chisq |> arrange(desc(p_value))
```


```{r warning = FALSE}
chisq |> filter(p_value > 0.05)
```

**No hay evidencia suficiente para decir que existe predictora independiente de la objetivo** (al 95% de confianza) seg煤n la prueba de independencia realizada


## Variables num茅ricas

Para las num茅ricas el proceso ser谩 ligeramente diferente, ya que ya no toman modalidades, aunque la mayor铆a de ellas como veremos podr铆an funcionar tanto de cuanti como de cuali (recategorizadas)

### Horas de Trabajo a la Semana

* `hours_per_week`: en realidad es una variable cualitativa m谩s que cuantitativa, y a partir de 2 noches en festivo representa menos de 1% --> podr铆amos probar a **dejarla tal cual o recategorizarla en 4 categor铆as** (ninguna - 1 - 2 - m谩s de 2)

```{r}
adultos |>
  count(hours_per_week, sort = TRUE) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc))
```

```{r}

adultos <- adultos |> 
 mutate(
    hours_per_week_transformed = as.factor(case_when(
      hours_per_week<40 ~ as.character("Menos de 40 Horas"),
      hours_per_week>40 ~ as.character("M谩s de 40 horas"),
      TRUE ~ as.character("40 Horas")
    )))

```

Ahora le daremos un orden a las nuevas categor铆as:

```{r}
adultos <-
  adultos |>
  mutate(hours_per_week_transformed = factor(hours_per_week_transformed, levels = c("Menos de 40 Horas", "40 Horas", "M谩s de 40 horas"),
                       ordered = TRUE))
knitr::kable(adultos |> select(hours_per_week_transformed) |> arrange(desc(hours_per_week_transformed)) |> unique() )
```

Y as铆 se ver铆a:

```{r}
adultos|> group_by(hours_per_week_transformed) |>  
  count(over_50k) |> 
  mutate(porc = 100*n/sum(n), cumul = cumsum(porc), nSum = sum(n)) |>  arrange(-nSum, -n) |> 
  select(-nSum) |> ungroup() 
```

## Colinealidad

Por 煤ltimo, nos falta comprobar los **problemas de  colinealidad** entre las predictoras num茅ricas. Podemos tratar las **num茅ricas por separado** (aunque tengamos muchas que en realidad hacen m谩s de cuali que de cuanti)


```{r}
library(corrr)
cor_matrix <- adultos |> select(where(is.numeric)) |> cor() |> round(2)

library(corrplot)
cor_matrix |>
  corrplot( method = 'ellipse', order = 'AOE', type = 'upper')
```


No parece existir una correlaci贸n elevada entre ninguna.


## Fase 3: modificaci贸n (fuera de la receta)

### Sampling

Con lo observado en la fase de exploraci贸n procederemos a hacer un **muestreo estratificado**  del 15% ya que tenemos muchas filas (al menos para hacer pruebas).


```{r}
# Muestreo del 25%
adultos_sample <-
  adultos |>
  group_by(over_50k) |> 
  slice_sample(prop = 0.15) |>
  ungroup()
```


## Fase 3: modificaci贸n (dentro de la receta)

### Partici贸n

#### Test vs lo dem谩s

Antes de nada deberemos realizar nuestras particiones, y primero dividiremos en **test y lo dem谩s**, con `initial_split()`, teniendo 25% en test y 75% en todo lo dem谩s

```{r}
# Partici贸n 10% de test 
adultos_split <- initial_split(adultos_sample, strata = over_50k, prop = 0.75)
adultos_split
```

F铆jate que en `adultos_split` solo tenemos las instrucciones. Vamos a aplicarlas

```{r}
# Aplicamos partici贸n
train_data <- training(adultos_split)
test_data <- testing(adultos_split)
```

Tras ello nunca est谩 de m谩s comprobar que efectivamente lo ha realizado de manera estratificada

```{r}
# Comprobamos estratos
train_data |> count(over_50k) |> mutate(porc = 100 * n / sum(n))
test_data |> count(over_50k) |> mutate(porc = 100 * n / sum(n))
```


#### Validaci贸n

Dado que no siempre disponemos de un volumen suficiente de datos, una **opci贸n muy com煤n y que arroja unos resultados bastante buenos** es la llamada **validaci贸n cruzada v-folds**: dividimos en $v$ trozos nuestro conjunto de entrenamiento, de forma que realizamos las siguientes iteraciones:

* Iteraci贸n 1: entrenamos el modelo con los conjuntos $\left\lbrace 2, 3, \ldots, v \right\rbrace$ y validamos con el primer conjunto.

* Iteraci贸n 2: entrenamos el modelo con los conjuntos $\left\lbrace 1, 3, \ldots, v \right\rbrace$ y validamos con el segundo conjunto.

...

* Iteraci贸n v: entrenamos el modelo con los conjuntos $\left\lbrace 1, 2, \ldots, v1 \right\rbrace$ y validamos con el conjunto $v$-茅simo.

Este m茅todo nos permite, no solo no tener que disponer de un alto volumen de datos sino que adem谩s **la validaci贸n ya no es sobre una sola muestra sino un promedio de varias** (eso s铆, muestras relacionadas entre s铆, no son independientes). Adem谩s con `strata` le diremos que dichas particiones las hagan estratificadas para conservar 0's-1's.


```{r}
# Fijamos la semilla
set.seed(100)

# Declaramos el n煤mero de particiones en las que procederemos a validar.
cv_folds <-
 vfold_cv(train_data, 
          v = 5, 
          strata = over_50k,
          repeats = 1) 
```

### Roles

Tras las particiones, el primer paso es **definir la receta**, indic谩ndole el conjunto donde tenemos validaci贸n y train, y enfrentar `over_50k` con todas. Despu茅s lo que haremos ser谩 **asignar posibles roles** que nos puedan diferencias las acciones entre las variables


```{r}
# Receta
rec_adultos <-
  # F贸rmula y datos
  recipe(data = train_data, over_50k ~ .)|>
  # Roles
  add_role(where(is.factor), new_role = "cuali") |> 
  add_role(where(is.numeric), new_role = "cuanti") |> 
  add_role(c(workclass, marital_status, occupation, native_country, hours_per_week, education, education_num), new_role = "Eliminar_KNN") |> 
  add_role(c(workclass, marital_status, occupation, native_country, hours_per_week, education, education_num), new_role = "Eliminar_Arboles") |> 
  add_role(c(workclass, marital_status, occupation, native_country, hours_per_week, education, education_num), new_role = "Eliminar_Random_Forests")
```


###Receta KNN

Ahora procederemos en crear la receta par el algoritmo KNN

```{r}
# Receta
KNN_rec_adultos <-
  rec_adultos  |> 
  # Modificaci贸n de variables actuales
  step_mutate(
    relationship =
                as.factor(case_when(
      relationship %in% c("Wife","Husband")  ~ "Boss",
      TRUE ~ "Others")),
    race =
                as.factor(case_when(
      race %in% c("Amer-Indian-Eskimo","Other")  ~ "Others",
      TRUE ~ as.character(race)))) |>
  # Eliminamos variables predefinidas.
  step_rm(has_role("Eliminar_KNN"))|> 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "iqr")) > 1.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes (podr铆amos dejarlas como una categor铆a m谩s)
  step_impute_knn(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Remover nulos
  step_naomit(everything(), skip = TRUE) |> 
  # Agrupamos en Minority los valores menos a 5%
  step_other(has_role("cuali"), threshold = .05, other = "Minority")  |> 
  # Escalamos los valores
  step_range(has_role("cuanti")) |> 
  # Normalizamos
  step_normalize(has_role("cuanti")) |> 
  # Dummyficamos
  step_dummy(all_nominal(), -all_outcomes())  |> 
  step_zv(all_predictors()) |> 
  step_corr(has_role("cuanti"), threshold = 0.7)  #|> 
```

Probaremos la receta para ver sus resultados:

```{r}
prepped_data <- 
  KNN_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(prepped_data)
```

### Receta CART

Ahora procederemos con la receta para crear el modelo de 谩rboles de decisi贸n.

```{r}
# Receta
cart_rec_adultos <-
  rec_adultos  |> 
  # Removeremos variables
  step_rm(has_role("Eliminar_Arboles"))|> 
  # Detectaremos outliers con base al "z"test.
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "z")) >2.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes
  step_impute_median(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Removemos valores nulos
  step_naomit(everything(), skip = TRUE) |> 
  # Agrupamos en Minority los valores menos a 5%
  step_other(has_role("cuali"), threshold = .05, other = "Minority")  |> 
  # Eliminamos variables con varianza 0
  step_zv(all_predictors()) |> 
  # Eliminamos variables con correlaci贸n mayor al 70%
  step_corr(has_role("cuanti"), threshold = 0.7)  |> 
  # Sobremuestreo 66% - 33%
  themis::step_upsample(over_50k, over_ratio = 0.5) 
```

Probamos la receta:

```{r}
cart_prepped_data <- 
  cart_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(cart_prepped_data)
```

### Receta Random Forest

Ahora procederemos a crear la receta para la modelaci贸n con el algoritmo Random Forest:

```{r}
# Receta
rf_rec_adultos <-
  rec_adultos  |> 
  # Agru
  step_rm(has_role("Eliminar_Random_Forests"))|> 
  # Detectar outliers
  step_mutate(across(where(is.numeric), function(x) { ifelse(abs(scores(x,type = "z")) >2.5 & !is.na(x), NA, x) })) |> 
  # Imputamos ausentes (podr铆amos dejarlas como una categor铆a m谩s)
  step_impute_knn(has_role("cuanti")) |> 
  step_impute_mode(has_role("cuali")) |> 
  # Removemos nulos
  step_naomit(everything(), skip = TRUE) |>
  # Agrupamos con Tag Minority a los grupos de valores en las variables que representen menos del 4%
  step_other(has_role("cuali"), threshold = .04, other = "Minority")  |> 
  # Reagrupamos
  step_zv(all_predictors()) |> 
  step_corr(has_role("cuanti"), threshold = 0.7)  |> 
  # Sobremuestreo 50-50%
  themis::step_upsample(over_50k, over_ratio = 1) 
```


Probamos la receta para el algoritmo de Random Forest:

```{r}
rf_prepped_data <- 
  rf_rec_adultos |>  # use the recipe object
  prep() |>  # perform the recipe on training data
  juice() # extract only the preprocessed dataframe 

glimpse(rf_prepped_data)
```

# Fase 4 Modelling

## Metodolog铆a

Primero evaluaremos cada uno de los modelos por separado (KNN, CART, Random Forest) utilizando slice_sample seleccionaremos aleatoriamente 10 diferentes combinaciones de par谩metros y con procesamiento en paralelo seleccionaremos el que tenga mejores resultados de cada uno de ellos. Al terminar la selecci贸n del mejor modelo, los compararemos entre ellos y seleccionaremos al mejor para hacer un Grid Search completo con validaci贸n cruzada y doble repetici贸n para encontrar el mejor resultado posible.


## C贸mputo en Paralelo

Vamos a **paralelizar en NUESTRO PROPIO ORDENADOR**: un ordenador suele tener **varios procesadores o cores** que pueden funcionar de manera 芦independiente禄 uno de otro. Vamos a detectar la cantidad de n煤cleos de los que podemos disponer con `detectCores()`.

```{r}


library(parallel)
library(doParallel)


# Detectamos los cores que tenemos
detectCores()
```

A la hora de paralelizar es importante que lo hagamos con cuidado ya que puede que nuestro ordenador se quede colgado: mi consejo es que definas el n煤mero de cores a usar como los que tienes menos uno.

Con `makeCluster()` montamos los **cl煤ster en cada nodo** y con `registerDoParallel()` registramos la paralelizaci贸n (puedes ver los hilos abiertos con `showConnections()`).

```{r}
# Iniciamos la paralelizaci贸n
clusters <- detectCores() - 1
make_cluster <- makeCluster(clusters)
registerDoParallel(make_cluster)
showConnections()
```

## Fase 4 KNN: modelo y flujo

### Flujo Modelo KNN

Empezamos a realizar el modelo KNN

```{r}
# Modelo
knn_model <-
  nearest_neighbor(mode = "classification", neighbors = tune("k"),
                   weight_func = tune("weight"), dist_power = tune("dist")) |>
  set_engine("kknn")

# Flujo de trabajo
knn_wflow_adultos <-
  workflow() |>
  add_recipe(KNN_rec_adultos) |>
  add_model(knn_model)
```

### Grid KNN

Ahora formaremos el grid para el modelo KNN

```{r}
grid_knn <-
  extract_parameter_set_dials(knn_wflow_adultos) |>
  # Actualizamos
  update(k = neighbors(range = c(90, 110)),
         weight = weight_func(values = c("inv","gaussian")),
         dist = dist_power(range = c(4, 6))) |>
  grid_regular(levels = 3) 
grid_knn <- grid_knn |> slice_sample(n=10) # 18 modelos (3 x 2 x 3)
grid_knn
```
### Aplicaci贸n del flujo de trabajo

```{r}
# Aplicamos el flujo
knn_res <- 
  knn_wflow_adultos |> 
  tune_grid(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens, f_meas),
    grid = grid_knn,
    control = control_grid(verbose = TRUE, allow_par = TRUE, #<<
                                   pkgs = c("outliers")),
 ) 

# finalizamos clusters
stopCluster(make_cluster)
registerDoSEQ()

# Recolectamos las m茅tricas de error
knn_res |> collect_metrics(summarize = TRUE)

```

### Matriz de Confusi贸n

Ahora es importante saber c贸mo se visualiza la matriz de confusi贸n

```{r}

knn_pred <- 
  knn_res |>
  collect_predictions() 


knn_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```

### Curva ROC 

Hacemos la curva ROC para medir la calidad de la predicci贸n

```{r}

knn_pred |> 
  group_by(id) |>
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot() +
  theme_economist_white()
```


# Densidad de Predicci贸n

Veamos la densidad de nuestra predicci贸n.

```{r}

knn_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```

Podemos ver c贸mo nuestro modelo se comporta totalmente diferente al poder definir las personas con un ingreso mayor a 50 K las cuales se encuentran en su mayor铆a a partir del 77% de probabilidad de pertenencia.

## Fase 4 CART: modelo y flujo

### Flujo Modelo CART

Empezamos a realizar el modelo CART

```{r}
# Modelo
cart_model <- decision_tree(mode = "classification", tree_depth = 7,
                min_n = 0.025 * nrow(test_data),
                cost_complexity = 0.1) |> set_engine("rpart")

# Flujo de trabajo
cart_wflow_adultos <-
  workflow() |>
  add_recipe(cart_rec_adultos) |>
  add_model(cart_model)

#Ejecuci贸n del flujo de trabajo
cart_res <- 
  cart_wflow_adultos |> 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens),
    control = control_resamples(save_pred = TRUE)
    )

# Colecci贸n de m茅tricas
cart_res |> collect_metrics(summarize = TRUE)
```



```{r}

cart_pred <- 
  cart_res |>
  collect_predictions()


cart_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```


```{r}
# Matriz de confusi贸n: etiqueta real vs etiqueta predicha
cart_pred |> 
  group_by(id) |> # id contains our folds
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot()

```



```{r}
cart_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```


### Visualizar el 谩rbol

Tambi茅n podemos visualizar f谩cilmente los 谩rboles generados con CART (Gini, del paquete `{rpart}`): primero con `extract_fit_engine()` extraemos las rutas del 谩rbol, y despu茅s con `rpart.plot(roundint = FALSE, extra = 4)` le indicamos que no redondee valores a enteros y de los modelos de visualizaci贸n elegimos `extra = 4` (prueba con varios para ver las diferencias). Para visualizar 谩rboles `C5.0` ver documentaci贸n en <https://topepo.github.io/C5.0/reference/plot.C5.0.html>

```{r visualizar}
library("rpart.plot")
# Aplicamo flujo

# Calculamos probabilidades

cart_best_model <- 
  cart_res |> select_best("roc_auc")

final_cart <- 
  cart_wflow_adultos |> 
  finalize_workflow(cart_best_model)

adultos_knn_fit <- 
  final_cart |>
  last_fit(adultos_split) 

# Calculamos m茅tricas en test (las indicadas)
adultos_knn_fit |> collect_metrics()

adultos_knn_fit |>
 extract_fit_engine() |>
  rpart.plot(roundint = FALSE, extra = 4)
```

### Importancia de las variables

```{r}
library(vip)

last_fit_rf %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip(num_features = 10)
```
## Fase 4 Random Forest: modelo y flujo


```{r}
library(ranger)


# Modelo
rf_spec <- 
  rand_forest() |> 
  set_engine("ranger", importance = "impurity") |> 
  set_mode("classification")


# Flujo de trabajo
rf_wflow <-
 workflow() |>
 add_recipe(rf_rec_adultos) |> 
 add_model(rf_spec) 

rf_res <- 
  rf_wflow |> 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, accuracy,roc_auc, sens),
    control = control_resamples(save_pred = TRUE)
    ) 

rf_res |> collect_metrics(summarize = TRUE)
```



```{r}

rf_pred <- 
  rf_res |>
  collect_predictions()


knn_pred |> 
  conf_mat(over_50k, .pred_class) |> 
  autoplot(type = "heatmap") 
```

```{r}
# Matriz de confusi贸n: etiqueta real vs etiqueta predicha
rf_pred |> 
  group_by(id) |> # id contains our folds
  roc_curve(over_50k, `.pred_<=50K`) |> 
  autoplot()

```



```{r}
rf_pred |> 
  ggplot() +
  geom_density(aes(x = `.pred_<=50K`, 
                   fill = over_50k), 
               alpha = 0.5) +
  theme_economist()
```


## Comparaci贸n de Modelos

```{r}


rf_metrics <- 
  rf_res %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Random Forest")

cart_metrics <- 
  cart_res %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "CART")

knn_metrics <- 
  knn_res %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "KNN")

# creamos un dataframe con todos los modelos
model_compare <- bind_rows(rf_metrics,
                           cart_metrics,
                           knn_metrics,
                           ) 

# Cambiando la estructura de datos
model_comp <- 
  model_compare %>% 
  select(model, .metric, mean, std_err) %>% 
  pivot_wider(names_from = .metric, values_from = c(mean, std_err)) 

# 
model_comp %>% 
  arrange(mean_roc_auc) %>% 
  mutate(model = fct_reorder(model, mean_roc_auc)) %>% # order results
  ggplot(aes(model, mean_roc_auc, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_brewer(palette = "Blues") +
   geom_text(
     size = 3,
     aes(label = round(mean_roc_auc, 2), y = mean_roc_auc + 0.08),
     vjust = 1
  )
```

```{r}
model_comp %>% slice_max(mean_roc_auc)
```
 
 
### Comparaci贸n Curva ROC
  
## Fase 4 Hyper Tunning 


Con base a los resultados podemos concluir que el modelo m谩s adecuado es el **Random Forest** con los siguientes par谩metros:



